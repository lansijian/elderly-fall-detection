 # 实验记录：CNN-LSTM模型在不平衡数据集上的性能评估

**日期**: 2025-6-24

---

## 1. 实验目标

本实验旨在评估CNN-LSTM混合模型在原始、未经过采样处理的不平衡KFall数据集上进行跌倒检测的性能。重点是分析模型在处理类别不平衡问题时的表现，并通过引入P-R曲线来更全面地衡量其在关键类别（跌倒）上的查准率和查全率。

## 2. 实验配置

- **模型**: `CNNLSTM` (包含1D-CNN、单向LSTM和Attention机制)
- **数据集**: KFall原始时序数据集，未进行任何采样或平衡处理。
  - **训练集标签分布**: 86.7% 非跌倒, 13.3% 跌倒
  - **测试集标签分布**: 87.4% 非跌倒, 12.6% 跌倒
- **核心脚本**: `KFall Dataset/cnn_lstm_fall_prediction_unbalanced.py`
- **关键超参数**:
  - `WINDOW_SIZE`: 100
  - `EPOCHS`: 50 (实际触发早停于第27轮)
  - `LEARNING_RATE`: 0.0005 (带学习率衰减)
  - `BATCH_SIZE`: 64

## 3. 核心结果

### 性能指标

| 指标 (类别)       | Precision | Recall | F1-Score |
|-------------------|-----------|--------|----------|
| **跌倒 (Fall)**   | 0.67      | 0.96   | 0.79     |
| **非跌倒 (Non-Fall)** | 0.99      | 0.93   | 0.96     |
| **总体准确率**      | -         | -      | 0.93     |

- **ROC AUC Score**: `0.9911`
- **Average Precision (AP) Score / PR-AUC**: `0.9568`

### 生成的图表文件

1.  `confusion_matrix_cnn_lstm_unbalanced.png`
2.  `pr_curve_cnn_lstm_unbalanced.png`
3.  `training_history_cnn_lstm_unbalanced.png`

## 4. 结果分析与结论

1.  **高召回率是主要优势**: 模型表现出极高的召回率（`0.96`），成功识别了测试集中绝大多数的真实跌倒事件。这对于安全关键型应用至关重要，因为漏报的代价极高。

2.  **精确率是主要短板**: 模型的精确率较低（`0.67`），这意味着在所有触发的"跌倒"警报中，约有三分之一是误报。这可能导致用户对系统的信任度下降或产生"警报疲劳"。

3.  **模型特性总结**: 该模型在默认阈值（0.5）下，其策略非常**激进和敏感**。它倾向于将任何可疑的模式都归类为跌倒，以最大程度地避免漏报。P-R曲线和混淆矩阵都清晰地反映了这种"宁可错杀，不愿放过"的行为模式。

4.  **不平衡数据下的有效性**: 尽管数据不平衡，但高达`0.99`的ROC AUC和`0.96`的AP分数证明了CNN-LSTM模型本身具备非常强大的特征提取和分类能力。性能的瓶颈不在于模型学不到，而在于如何对预测概率进行决策。

## 5. 阈值调优分析

鉴于原始模型在默认阈值（0.5）下存在"高召回、低精确"的问题，我们执行了阈值寻优，旨在找到一个更均衡的性能点。

- **初步调优脚本**: `KFall Dataset/tune_threshold_unbalanced.py`
- **精细化调优脚本**: `KFall Dataset/fine_tune_threshold.py`
- **新生成图表**: 
  - `threshold_tuning_cnn_lstm_unbalanced.png`
  - `threshold_tuning_cnn_lstm_unbalanced_fine_grained.png`

### 初步调优结果

通过遍历从0.1到0.95的阈值，我们发现 **F1分数在阈值为 0.80 时达到最大值**。

**阈值 `0.80` 下的性能 vs 默认阈值 `0.5`**

| 阈值 (Threshold) | Precision | Recall | F1-Score |
|:----------------:|:---------:|:------:|:--------:|
| 0.50 (默认)      | 0.67      | 0.96   | 0.79     |
| **0.80 (初步最佳)**  | **0.90**  | **0.87** | **0.88** |

### 精细化调优结果

为了获得更精确的最佳阈值，我们进一步在0.75到0.85之间以0.01的步长进行了精细化搜索。结果如下：

| 阈值 (Threshold) | Precision | Recall | F1-Score |
|:----------------:|:---------:|:------:|:--------:|
| 0.79             | 0.8832    | 0.8832 | 0.8832   |
| 0.80             | 0.8950    | 0.8746 | 0.8847   |
| 0.82             | 0.9024    | 0.8689 | 0.8853   |
| **0.84 (最终最佳)** | **0.9075** | **0.8661** | **0.8863** |

精细化搜索发现，**阈值0.84**时F1分数达到最高值0.8863。此外，我们观察到在阈值0.79时，精确率和召回率达到完全平衡（均为0.8832）。

## 6. 最终结论与建议

通过精细化阈值调优，我们成功地在不重新训练模型的情况下，显著提升了模型的实用性。

- **优化效果**: 我们用**降低9.5%召回率**（从0.96降至0.8661）的可控代价，换来了**提升24%精确率**（从0.67提升至0.9075）的巨大收益，使得误报率大幅降低。

- **最终建议**: 在此模型的实际部署中，**强烈推荐使用 `0.84` 作为最终的分类阈值**。这能使系统在保持高跌倒事件捕获率的同时，提供更可靠、更少干扰的警报，达到性能和用户体验的最佳平衡。

- **可选替代方案**: 如果应用场景对精确率和召回率有特殊要求，可以考虑:
  - 阈值`0.79`: 精确率和召回率完全平衡（均为0.8832）
  - 阈值`0.85`: 更高的精确率（0.9096），但召回率略低（0.8604）

## 7. 后续步骤建议

- **对比实验**: 可以与使用**平衡后数据集**训练的模型进行对比，以量化数据平衡策略对精确率和召回率的具体影响。
- **模型部署**: 在实际部署时，建议使用0.84作为默认阈值，但可以为用户提供调整选项，以适应不同的应用场景需求。